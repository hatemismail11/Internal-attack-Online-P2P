\section{Internal Attack Model}
\label{sec:Attack}

In this section, we introduce the concept of internal attacks in the context of streaming P2P overlays.
Our focus are attacks on availability that aim to intercept video chunks from the source. 
We start by introducing attack characteristics such as target, budget, and placement of malicious nodes. 
Afterwards, our main discussion outlines the the various adversarial behaviors that can be applied by a malicious peer once a video chunk has been intercepted. 

\subsection{Target, budget and placement}


The target of the internal attack is to severely degrade the user's satisfaction by interrupting the video stream close to the source, thus preventing dissemination between benign peers.
Accordingly, the attacker aims at using its budget to occupy the source's neighbor list, where budget denotes the malicious peers $m\in M$ the attacker can place in the system.
Note that in a real streaming system, the typical size of the source's neighbor list is 20-30 entries \cite{neighborlist1,neighborlist2}, which highlights the feasibility of conducting the internal attack using a very small budget.

Assume an attacker with budget $x$ is capable of assigning malicious peers as headnodes.
In fact, it is feasible to do so, for example through (a) joining the overlay as early as possible in case of a pre-announced time for a streamline, (b) taking down the source's benign headnodes, or (c) Abusing peers' replacement mechanisms \cite{nguyen2016swap}.
Hence, the attacker initially assigns a fraction $\eta x$, where $\eta\in [0,1]$, of its resources as headnodes.
As the attacker's main objective is to fully occupy the source's neighbor list, the optimum value of $\eta$, from the attacker's perspective, is when $\eta x = |NeighborList|$.
In case such full exploitation of the source's neighbor list is not feasible when the attack is being initiated, the attacker continuously tries to increase the value of $\eta$.  

The rest of malicious peers $MN=x-\eta x$ are assigned as neighbors to the $\eta x$ malicious headnodes, i.e., those peers are not headnodes, they are connected as neighbors to the malicious headnodes. 
Nonetheless, such placement is considered the best strategy for the attacker for the following reasons: (a) $MN$ is used to counter headnodes replacement mechanisms such as SWAP \cite{nguyen2016swap}, i.e., malicious headnodes $\eta x$ keep on advertising $MN$ to the source for swapping, and thus, $MN$ are promoted as headnodes
, and (b) as benign peers in malicious headnodes neighbors 


Given the fact that inferring the overlay's topology is indeed feasible \cite{nguyen2016swap,rbcs}, accordingly, the attacker is capable of inferring the existing headnodes in the system.
Accordingly, such distribution of the attacker's budget assures that even if the attacker is not able to directly place malicious peers as the source's neighbors (headnodes), having a higher budget to occupy the headnodes' neighbor lists also results on a complete shut down of the stream from the rest of the overlay.

\subsection{Adversarial behaviors}
Here we discuss three basic adversarial behaviors that are executed either simultaneously with a certain probability or standalone according to the attacker's target, budget and the susceptibility to being detected.
In Section~\ref{sec:eval}, we provide a simulation study to demonstrate the impact of the different attack scenarios below.

\subsubsection*{Dropping behavior}
When a malicious peer $m$ receives a video-chunk from the source or even through another headnode, $m$ drops the packet. 
Hence, $m$ never advertises for those chunks and instead, keeps on requesting the dropped chunks from other benign peers $b \in B$.
This scenario guarantees that: (a) malicious peers are less susceptible to being suspected given that the requesting benign peers are not aware that $m$ indeed received those chunks,
and (b) are incapable of inferring that the malicious headnodes fraction $\eta x$ is an actual headnode as the availability and the freshness of chunks in the buffer-maps are a key factor to infer the position of a peer.


\subsubsection*{Manipulating behavior}
When executing manipulating behavior, $m$ sends its updated buffer-map to $b$, i.e., it advertises received chunks. 
Although having the actual video chunks $m$ advertised for, $m$ never sends the requested video chunks from $b$.
In this scenario, malicious peers are more susceptible to being detected, however, a benign peer might be overloaded and can not serve all the requests it receive and might also appear manipulating to other benign peers.
In Section~\ref{sec:detection}, we further discuss this case and propose a procedure that decreases the likelihood of suspecting a benign peer of being malicious.

\subsubsection*{Outdated time stamps behavior}
In this behavior, $m$ simply advertises for the chunks in its buffer-map. 
However, $m$ starts serving the requests once the requested chunks are considered out-dated.
Similar to the manipulating behavior, malicious peers are more susceptible to being detected than in the dropping behavior case.




