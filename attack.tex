\section{Internal Attack Model}
\label{sec:Attack}

In this section, we introduce the concept of internal attacks in streaming P2P overlays.
Our focus is on attacks on availability that aim to intercept data chunks from the source. 
We start by introducing the attack characteristics such as target, budget, and malicious nodes placement. 
Subsequently, our main discussion outlines the \drop adversarial behavior. 

\subsection{Target, budget and placement}


The target of the internal attack is to severely degrade the user's satisfaction by interrupting the stream close to the source, thus preventing dissemination between benign peers.
The budget $x$ of the attacker corresponds to the number of nodes controlled by the malicious party. 
In accordance with the attack goal of maximizing impact, the attacker aims to use its budget to occupy the source's neighbor list. 
Note that in a real streaming system, the typical size of the source's neighbor list is 20-30 entries~\cite{neighborlist1,neighborlist2}, which highlights the feasibility of conducting an internal attack using a very small budget.


We assume an attacker to (a) have a budget $x$, and (b) be capable of assigning malicious peers as headnodes.
Potential ways of assigning headnodes include (1) joining the overlay as early as possible in case of a pre-announced time for a streamline, (2) taking down the source's benign headnodes, or (3) abusing peers' replacement mechanisms~\cite{nguyen2016swap}.
Hence, the attacker initially assigns $x_h \leq x$ of its resources as headnodes.
As the attacker's main objective is to fully occupy the source's neighbor list, the optimum value of $x_h$ for the attacker, is $x_h = |NeighborList|$.
If full exploitation of the source's neighbor list is not feasible when the attack is being initiated, the attacker continuously tries to increase the value of $x_h$.  

The rest of malicious peers $x-x_h$ are connected as neighbors to the $x_h$ headnodes. 
Such a placement is the best strategy for the attacker since the impact caused by the $x-x_h$ peers is maximized due to their relative closeness to the source, i.e., a larger fraction of benign peers experience a longer service degradation till a sufficient amount of benign peers receive and start disseminating the stream.
% is used to counter headnodes replacement mechanisms such as SWAP \cite{nguyen2016swap}, i.e., malicious headnodes $x$ keep on advertising the $x-x_h$ malicious peers to the source for swapping, and thus, $x-x_h$ malicious peers are eventually promoted to headnodes. 
Given the fact that inferring the overlay's topology is indeed feasible~\cite{nguyen2016swap,rbcs}, the attacker is capable of inferring the existing headnodes to optimally place malicious peers as headnodes.
Nonetheless, even if the attacker is not able to directly place malicious peers as headnodes, having a higher budget to occupy the headnodes' neighbor lists also results on a complete shut down of the stream from the rest of the overlay.



\subsection{\drop adversarial behavior}
We now discuss the main adversarial behavior that gets executed based on the attacker's target and budget. 
Let $M$ be the set of malicious peers that collaboratively execute \drop. 
When $m \in M$ receives a chunk from a neighbor, $m$ drops the chunk.
In particular, $m$ never advertises chunks in its $BM$, except to the neighbor it received the chunk from.
Indeed, it keeps on requesting the dropped chunks from other benign peers $b \in B$, where $B$ is the set of benign peers.
This scenario guarantees that: (a) malicious peers are less susceptible to being suspected as the requesting benign peers are not aware that $m$ indeed received those chunks,
and (b) detecting $m$'s direct or close connection to the source, inferring the overlay's topology, is not possible, which lowers the probability of $m$ being suspected.


Note that this behavior minimizes the detection susceptibility of malicious peers.
The reason is that other $BM$ cheating strategies result in eventually declaring a certain suspect, e.g, if $m$ keeps on sending correct $BM$ updates but never sends the actual chunk, honest nodes will eventually suspect $m$.


 





