\section{Internal Attack Model}
\label{sec:Attack}

In this section, we describe the details of launching an internal attack on a streaming P2P overlay that targets intercepting video chunks from the source. 
% We consider an attack that is not specific to a certain streaming P2P data dissemination technique, i.e., hybrid, push or pull-based.
First, the attack's target, budget and malicious peers' placement are discussed.
Afterwards, the different adversarial behaviors that can be applied by a malicious peer once a video chunk is intercepted are detailed.

\subsection{Target, budget \& placement}

The target of the internal attack is to severely degrade the user's experience by cutting out the stream from the source before being available for dissemination between benign peers.
Accordingly, the attacker aims at placing malicious peers $m\in M$ in the source's neighbor list.
Note that in a real streaming system, the typical size of the source's neighbor list is 30-40 entry [ref8, ref9], which highlights the feasibility of conducting the internal attack using a very small budget.


Assume an attacker with budget $x$ is capable of joining the overlay as early as possible, for example, a pre-announced time for a streamline or via taking down the source's benign headnodes.
The attacker assigns a fraction $\eta x$, where $\eta\in [0,1]$, of its resources as headnodes.
The remaining malicious peers $MN=x-\eta x$ are assigned as neighbors to the $\eta x$ malicious headnodes, i.e., those peers are not headnodes, they are connected as neighbors to the malicious headnodes.
In this manner, $MN$ can be also used even if SWAP \cite{nguyen2016swap} mechanism is executed, i.e., malicious peers keep on advertising $MN$ to the source for swapping.
Thus, even if the attacker is not able to directly place malicious peers as the source's neighbors, having a higher budget to occupy the headnodes' neighbor lists also results on a complete shut down of the stream from the rest of the overlay.

\subsection{Adversarial behaviors}
Here we discuss three basic adversarial behaviors that are executed either with a certain probability or independently according to the attacker's budget and the risk of being detected.
In Section~\ref{sec:eval}, we provide a simulation study with the impact of different attack scenarios.

\subsubsection*{Dropping behavior}
Once a malicious peer $m$ receives a video-chunk from the source or even through another head-node, $m$ drops the packet. 
Hence, $m$ never advertises for those chunks and instead, keeps on requesting the dropped chunks from other benign peers $b \in B$.

\subsubsection*{Manipulating behavior}
In a manipulating behavior, $m$ sends its updated $BM$ to $b$.
Although having the actual video chunks $m$ advertised for, $m$ never sends those video chunks once requested from $b$.

\subsubsection*{Outdated time stamps behavior}
In this behavior, $m$ simply advertises for the chunks in its $BM$. 
However, $m$ only sends those chunks to any requesting peer when they are outdated.
This technique is mainly used by the attacker to lower the risk of being detected, unlike the manipulating behavior.



