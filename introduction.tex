\section{Introduction}
\label{sec:intro}

Streaming content is an essential component of data-driven infrastructures~\cite{emule}.
Most streaming applications rely on (monopolistic) central providers that have significant computing and communication resources to distribute high quality of service content to a large audience in a fast and reliable manner. 
For the providers, this entails the use of dedicated resources, involves performance and scalability issues along with considerations of handling single point of failures.
Distributing content via a Peer-to-Peer (P2P) network significantly lowers the load that the provider experiences as the participants relay the downloaded content to other participants. 
This eliminates the need that all participants receive their content directly from the source, i.e., the provider. 
Consequentially, P2P streaming becomes an attractive option for alternative distributed providers and user-generated content to help reduce data delivery costs and results in lower rates for customers.


However, achieving high reliability in a P2P overlay and across a dynamic and heterogeneous group of content distributors is challenging. In addition to the inherent operational unreliability of benign participants, attackers such as competitors can infiltrate the set of peers and conduct denial-of-service attacks. In this manner, malicious participants can interrupt or delay the distribution of the content with the goal of degrading the quality of service. 

In general, nodes in a P2P streaming system connect to a small set of other nodes, called the \emph{neighbor set}. 
The publisher or the \emph{source} of the content divides the stream into \emph{chunks}, which each contain an equal-sized part of the encoded data, and forwards these chunks to its neighbors. Nodes in the system receive chunks from neighbors and forward them to neighbors that have not previously received the respective chunks. 
The selection of neighbors and the choice of neighbors to receive-from or forward-to differs across protocols~\cite{sasi2014survey}.  Yet, pull-based mesh networks are the predominant method in P2P streaming systems~\cite{zhang2014modeling}. In a mesh overlay, peers maintain a buffer-map indicating which chunks they possess.  Neighbors periodically exchange their buffer-maps and request chunks from neighbors whose buffer-maps indicate possession of the respective chunk. Peers then forward chunks based on the received requests. 


In pull-based systems, there exist several denial-of-service attacks, known as buffer-map or $BM$ cheating attacks~\cite{cheatingAnalysis}. 
In such an attack, malicious nodes might drop or delay chunks. Alternatively, they might advertise chunks that they do not have. As detection of the latter is locally possible and the effect of delaying chunks is at most as severe as entirely dropping the respective chunks, we focus on a denial-of-service attack through dropping chunks without advertising them, called \drop in the following.  


In the past, multiple countermeasures aimed to reduce the severity of the \drop attack. However, the majority of these defences~\cite{zhang2005coolstreaming, defending2, antiliar} assume that the attacker is unaware of the topology of the streaming network and specifically does not know the \emph{headnodes}, i.e., the peers connected to the source. 
However, previous work indicates that it is relatively easy to infer the identity of benign headnodes and then target those important nodes~\cite{nguyen2016swap}.
While countermeasures to these inference attacks exist, they assume an external adversary that can shut-down or replace certain nodes~\cite{nguyen2016swap, rbcs, nguyen2014resilience}. 
Hence, the existing work evaluates neither the impact of nor protection mechanism against internal colluding attackers, i.e., attackers that insert nodes under their control into the system pretending to be regular participants. 


In this paper, we first illustrate the effectiveness of internal attacks based on malicious headnodes. 
Consequently, we propose a mechanism for detecting \drop by keeping track of peer satisfaction. If the cumulative satisfaction level of a group of peers drops below a certain threshold, the source replaces all headnodes associated with the group with randomly chosen peers. 
Hence, our detection and mitigation mechanism efficiently reacts to a detected low quality of service  rather than explicitly identifying the misbehavior of one or more specific nodes.
Note that we focus on attackers that control a low fraction of nodes, as attackers controlling the majority of nodes can trivially control most of the communication, even without gaining strategic positions such as headnodes.    

Using a simulation study, we show that the proposed detection mechanism effectively restores peers satisfaction, even in a scenario where the attacker controls all headnodes. 
Our mechanism introduces only a small signaling overhead of approximately $8\%$ supporting the claim of being efficient.

A theoretical analysis complements our practical results, focusing on the opportunities to abuse the detection mechanism. 
Indeed, the detection algorithm prevents malicious nodes from replacing benign headnodes with malicious nodes unless they control a large fraction of the total number of nodes. 
Furthermore, maintaining malicious headnodes despite generally low satisfaction levels is not possible for the considered attacker. 
  
% 
% at detection malicious behaviors in a fast, low overhead approach while considering the case where the attacker can fully occupy the source's neighbor list with malicious headnodes.
% In details, peers are able to trigger a request to their neighbors once (a) a peer is, with evidence, performing maliciously, or (b) generally, the stream satisfaction (the user's experience) of a peer drops below a given application threshold.
% Once proven malicious, a peer fires a complaint, on behalf of all other participants in the detection process, to the source to remove the detected peer from it's neighbor list,
% or to generally decide about peers that might be affecting the satisfaction level of non-headnodes.
% \subsection*{Paper Structure}
% \mn[Stef]{I dislike paper structure sections, but that is personal taste; I can deal with them by ignoring them, which is what I did with this one}
% The rest of the paper is organized as follows: Section~\ref{sec:related} discusses the related work and the background.
% In Section~\ref{sec:Attack}, the concepts underlying the attacker model internal attack and the conducted adversarial behaviors are defined.
% The detection mechanism is fully discussed in Section~\ref{sec:detection}, with the theoretical analysis is discussed in Section~\ref{sec:analysis}.
% The internal attack's impact, along with the detection mechanism performance and efficiency, are evaluated in Section~\ref{sec:eval}. Finally, we conclude our work and discuss the future work in Section~\ref{sec:conclusion}.
